---
title: The Theory of Constraints - Part II
date: August 28, 2015
---

In case you missed last week's article, you can find [Part 1 here](http://www.higherorderheroku.com/articles/the-theory-of-constraints/)

##Goals in Context
We talked a little bit in last week’s article about defining a “goal” with respect to what your “factory”, a web application in this context, is producing.  As I suggested then, a metric that I commonly hear cited as important is 'request response time'.  This could take the form of a page load or an api call but the idea is basically the same: A minimal amount of time should elapse between the time a request is initiated and when a result is returned.  A commonly cited target for this metric is "sub-second response".  While there is absolutely nothing wrong with this metric or a sub-second response, I can't help but feel like this a “go to” aspiration rather than a deeply considered goal.  Like Mom and apple pie, generally nobody has a problem with a zippy web app but are we honestly considering the big picture?  As with most other engineering disciplines, as you optimize one edge of the triangle, so too must you diminish another.  Other goals to consider might be: total transaction volume, end-user experience or cost and complexity.  Let's explore some of these other goals a little further.

For example, it may be that I have a transaction oriented business, e.g. the more transactions I process, the more revenue I generate.  In this context, might make sense to spend extra time pre-processing, outsourcing or queuing requests at the expense of response time to get more throughput out of your factory.  In an example that considers the end-user experience, you might want to combine finer-grained steps into coarser grained flows.  This is called "batching".  This might increase your response time, but it may produce a shorter overall work flow (e.g. sign-up?) and thus a happier end-user experience.  And finally we have to consider cost and complexity.  Like a factory, you have to build your web application to contain certain “machinery” that executes the work.  Specifically with regard to the Heroku platform, the machinery are things like dynos, databases, add-ons and anything else that supports your running application code.  You can build your factory as a big monolithic structure or you can sub-divide the various assemblies and partition them out to a bunch of sub-factories.  These of course are different approaches to physical architectures that are commonly known as monolithic and micro-services respectively.

##The Factory Blueprint
So with your goal now in better focus, I hope, it’s time to start thinking about how the machinery is assembled.  One of the first questions I ask is how much demand is going to be put on your factory, er, I mean web application.  In economic parlance, capacity must be >= demand.  I’m often surprised how folks approach this demand question.  Answers tend to range from one extreme “We have absolutely no idea.” to “We’re sure that we’ll get 10 trillion hits in the first hour of our launch”.  In general, neither one of these answers tend to be very helpful or realistic.  I can't emphasize enough how important an informed estimate of expected demand is.  I generally try to guide folks through a predictive exercise that aims to make an educated guess that lands within a range.  For example, if Stephen Colbert does actually tweet about your site and he has 1M Twitter followers and assuming 10% most likely case and 15% best case of those followers actually click on the URL, then you can expect 100-150K visits within the first hour.  This is based on realistic assumptions rather than the unlikely assumption that you're going to go viral.  The point here is that you have to consider some kind of demand planning to size the capacity of your factory and you have to base that capacity on reasonable assumptions.  Assumptions by their very nature are not 100% accurate, they're nothing more than educated guesses and that's ok.  The idea is to model a realistic and most likely reality and plan capacity accordingly.

## Conclusion
So with a projected capacity target and a well-formed goal in mind, we’re well on our way to being able to lay assets and resources out in such a way that gets us to the point where we’re humming along like a well oiled machine.  For the next installment, I’ll talk more in-depth about TOC (The theory of constraints) as it relates to throughput, capacity, work and of course the dreaded “Herbie”.  Until next week!